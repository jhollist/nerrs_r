---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r setup, echo=FALSE, warning=FALSE, purl=FALSE, message=FALSE}
library(knitr)
options(repos="http://cran.rstudio.com/")
opts_chunk$set(fig.path="figures/",R.options=list(max.print=100),message = FALSE,
               warning = FALSE, error = FALSE)
if(!require("ggplot2")){
  install.packages("ggplot2")
}
if(!require("dplyr")){
  install.packages("dplyr")
}
if(!require("tidyr")){
  install.packages("tidyr")
}
library("ggplot2")
library("dplyr")
library("tidyr")
library("readr")
library("readxl")
library("palmerpenguins")
```

# Tidy Data in R

In this lesson we will cover the basics of data in R and will do so from a somewhat opinionated viewpoint of "Tidy Data".  There are other paradigms and other ways to work with data in R, but focusing on Tidy Data concepts and tools (a.k.a., The Tidyverse) gets people to a productive place the quickest.  For more on data analysis using the Tidyverse, the best resource I know of is [R for Data Science](http://r4ds.had.co.nz).  The approaches we will cover are very much inspired by this book.

## Lesson Outline
- [Tidy data](#tidy-data)

## Exercises
- [Homework 3.2](#exercise-32)


## Tidy data

We have learned about data frames, how to create them, and about several ways to read in external data into a data.frame.   At this point there have been only a few rules applied to our data frames (which already separates them from spreadsheets) and that is our datasets must be rectangular.  Beyond that we haven't disscussed how best to organize that data so that subsequent analyses are easier to accomplish. This is, in my opinion, the biggest decision we make as data analysts and it takes a lot of time to think about how best to organize data and to actually re-organize that data.  Luckily, we can use an existing concept for this that will help guide our decisions and re-organization.  The best concept I know of to do this is the concept of [tidy data](http://r4ds.had.co.nz/tidy-data.html).  The essence of which can be summed up as:

1. Each column is a variable
2. Each row is an observation
3. Each cell has a single value
4. The data must be rectangular

Lastly, if you want to read more about this there are several good sources:

- The previously linked R4DS Chapter on [tidy data](http://r4ds.had.co.nz/tidy-data.html)
- The [original paper by Hadley Wickham](https://www.jstatsoft.org/article/view/v059i10)
- The [Tidy Data Vignette](http://tidyr.tidyverse.org/articles/tidy-data.html)
- Really anything on the [Tidyverse page](https://www.tidyverse.org/)
- A lot of what is in the [Data Carpentry Ecology Spreadsheet Lesson](https://datacarpentry.org/spreadsheet-ecology-lesson/) is also very relevant.

Let's now see some of the basic tools for tidying data using the `tidyr` and `dplyr` packages.

### Data manipulation with `dplyr`

There are a lot of different ways to manipulate data in R, but one that is part of the core of the Tidyverse is `dplyr`.  In particular, we are going to look at selecting columns, filtering data, adding new columns, grouping data, and summarizing data.  

#### select

Often we get datasets that have many columns or columns that need to be re-ordered.  We can accomplish both of these with `select`.  Here's a quick example with the `penguins` dataset.  We will also be introducing the concept of the pipe: `%>%` which we will be using going forward.  Let's look at some code that we can dissect.

First, without the pipe:

```{r}
penguin_bill <- select(penguins, species, bill_depth_mm, bill_length_mm)
penguin_bill
```

Then the same thing, but using the pipe instead:

```{r}
penguin_bill <- penguins %>%
  select(species, bill_depth_mm, bill_length_mm)
penguin_bill
```

The end result of this is a data frame, `penguin_bill` that has three columns: species,  bill_depth_mm and bill_length_mm in the order that we specified.  And the syntax we are now using is "piped" in that we use the `%>%` operator to send something from before the operator (a.k.a. "to the left") to the first argument of the function after the operator (a.k.a. "to the right").  This allows us to write our code in the same order as we think of it.  The best explanation of this is (again) from R For Data Science in the [Piping chapter](http://r4ds.had.co.nz/pipes.html).

#### filter

The `filter()` function allows us to fiter our data that meets certain criteria.  For instance, we might want to further manipulate our 3 column data frame with only one species of Iris and Petals greater than the median petal width.

```{r}
penguin_bill_gentoo <- penguins %>%
  select(species = species, bill_depth = bill_depth_mm, bill_length = bill_length_mm) %>%
  filter(species == "Gentoo") 
penguin_bill_gentoo  
```

And we can combine a few more steps:

```{r}
penguin_bill_gentoo_big <- penguins %>%
  select(species = species, bill_depth = bill_depth_mm, bill_length = bill_length_mm) %>%
  filter(species == "Gentoo") %>%
  filter(bill_length >= median(bill_length, na.rm = TRUE)) 
penguin_bill_gentoo_big
```

Pay attention to a few things here.  First, what happened to our column names as we worked our way through the piped workflow (e.g. look at what we did to `bill_length`).  Also, see how we were able to nest some other functions here.

#### mutate

Now say we have some research that suggest the ratio of the bill depth and bill length is important.  We might want to add that as a new column in our data set.  The `mutate` function does this for us.

```{r}
penguin_bill_ratio <- penguins %>%
  select(species = species, bill_depth = bill_depth_mm, bill_length = bill_length_mm) %>%
  mutate(bill_ratio = bill_depth/bill_length)
penguin_bill_ratio
```

#### group_by and summarize

What if we want to get some summary statistics of our important bill ratio metric for each of the species?  Grouping the data by species, and then summarizing those groupings will let us accomplish this.

```{r}
penguin_bill_ratio_species <- penguins %>%
  select(species = species, bill_depth = bill_depth_mm, bill_length = bill_length_mm) %>%
  mutate(bill_ratio = bill_depth/bill_length) %>%
  group_by(species) %>%
  summarize(mean_petal_ratio = mean(bill_ratio, na.rm = TRUE),
            sd_petal_ratio = sd(bill_ratio, na.rm = TRUE),
            median_petal_ratio = median(bill_ratio, na.rm = TRUE))
penguin_bill_ratio_species
```


#### left_join

Lastly, we might also have information spread across multiple data frames.  This is the same concept as having multiple tables in a relational database.  There are MANY ways to combine (aka. "join) tables like this and most of them have a `dplyr` verb implemented for them.  We are going to focus on one, the `left_join()`.

Instead of continuing with the `penguins` data we will create some data frames to work with for these examples.

```{r join_data}
left_table <- data.frame(left_id = 1:6, 
                         names = c("Bob", "Sue", "Jeff", "Alice", "Joe", "Betty"))
right_table <- data.frame(right_id = 1:5, 
                          left_id = c(2,1,3,6,7), 
                          age = c(17,26,45,32,6)) 
left_table
right_table
```

To combine these two tables into one we can `join` them.  In particular we will use a `left_join()` which keeps all records from the first table (i.e the "left" table) and adds only the matching records in the second table (i.e. the "right" table).  This is easier to understand by looking at the results.

```{r left_join}
left_right_table <- left_table %>%
  left_join(right_table, by = c("left_id" = "left_id"))
left_right_table
```

## Homework 3.2

For this homework we will work on tidying up our datasets dig into our datasets and find ways to tidy them up.  We first need to clean up the new data frame,`ne_nerrs_sites`, that we loaded up in Homework 3.1.  Add new lines of code after the section of code that cleans up the `ne_nerrs_wq` data frame (e.g. right before the commented lines about visualizing data). Add some comments to your script that describe what we are doing.  I fully acknowledge that this is a lot and should challenge you.  I can set up "office hours" ahead of time if you need help.  We will discuss in class (or via email if I forget).

1. All of this work should be stored to a new data frame called `ne_nerrs_wq_latlong`.
2. Create a new column in the `ne_nerrs_sites` data frame, called `reserve` that contains just the reserve code.  You will need to figure out which `dplyr` verb to use, but this code should help assign that `substr(station_code, 1, 3)`.
3. We now want to use this new `reserve` column, and calculate an average latitude and longitude for each reserve, saving these to `lat_avg` and `long_avg`, respectively.  Think grouping and summarizing here.
5. Join all of this with the `ne_nerrs_wq` data frame. 
6. The end result should be a data frame with all of our water quality variables, plus the average coordinates for each reserve. 


  
